{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3 \"Сверточные нейронные сети\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import cache\n",
    "from itertools import islice\n",
    "from typing import IO, Any, Callable, Mapping, Optional, Sequence, Sized, Tuple, cast\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as image\n",
    "from PIL.Image import Image\n",
    "from torch import Tensor, cuda, device, mps, no_grad, optim\n",
    "from torch import max as torch_max\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "\n",
    "def RPSClassifier() -> nn.Sequential:\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256 * 18 * 18, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 3),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "\n",
    "class ZipImageDataset[TSample, TTarget](VisionDataset):\n",
    "    _zip: ZipFile\n",
    "    _loader: Callable[[IO[bytes]], Image]\n",
    "    _classes: Sequence[str]\n",
    "    _target_mapper: Mapping[str, int]\n",
    "    _dataset: Sequence[Tuple[str, int]]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        zip_filename: str,\n",
    "        loader: Optional[Callable[[IO[bytes]], Image]] = None,\n",
    "        transform: Optional[Callable[[Image], TSample]] = None,\n",
    "        target_transform: Optional[Callable[[int], TTarget]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            zip_filename, transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self._zip = ZipFile(zip_filename, \"r\")\n",
    "        self._loader = loader or ZipImageDataset.default_loader\n",
    "\n",
    "        self._classes = self._build_classes()\n",
    "        self._target_mapper = self._build_target_mapper()\n",
    "        self._dataset = self._build_dataset()\n",
    "\n",
    "    @property\n",
    "    def classes(self) -> Sequence[str]:\n",
    "        return self._classes\n",
    "\n",
    "    def close(self) -> None:\n",
    "        self._zip.close()\n",
    "\n",
    "    def _build_classes(self) -> Sequence[str]:\n",
    "        directories = [e for e in self._zip.infolist() if e.is_dir()]\n",
    "        max_deep = max(e.filename.count(\"/\") for e in directories)\n",
    "\n",
    "        return sorted(\n",
    "            ZipImageDataset._get_target(e.filename)\n",
    "            for e in directories\n",
    "            if e.filename.count(\"/\") == max_deep\n",
    "        )\n",
    "\n",
    "    def _build_target_mapper(self) -> Mapping[str, int]:\n",
    "        return {e: i for i, e in enumerate(self._classes)}\n",
    "\n",
    "    def _build_dataset(self) -> Sequence[Tuple[str, int]]:\n",
    "        return [\n",
    "            (e.filename, self._target_mapper[ZipImageDataset._get_target(e.filename)])\n",
    "            for e in self._zip.infolist()\n",
    "            if not e.is_dir()\n",
    "        ]\n",
    "\n",
    "    def _unpack_file(self, filename: str) -> IO[bytes]:\n",
    "        return self._zip.open(filename)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._dataset)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[TSample, TTarget]:\n",
    "        path, target = self._dataset[index]\n",
    "\n",
    "        with self._unpack_file(path) as stream:\n",
    "            sample = self._loader(stream)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return cast(TSample, sample), cast(TTarget, target)\n",
    "\n",
    "    def __enter__(self) -> \"ZipImageDataset\":\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *_) -> None:\n",
    "        self.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_target(path: str) -> str:\n",
    "        return path.split(\"/\")[-2]\n",
    "\n",
    "    @staticmethod\n",
    "    def default_loader(stream: IO[bytes]) -> Any:\n",
    "        img = image.open(stream)\n",
    "        return img.convert(\"RGB\")\n",
    "\n",
    "\n",
    "class CachedDataset[TSample, TTarget](Dataset):\n",
    "    def __init__(self, dataset: Dataset) -> None:\n",
    "        self._dataset = dataset\n",
    "\n",
    "    @cache\n",
    "    def __len__(self) -> int:\n",
    "        if isinstance(self._dataset, Sized):\n",
    "            return len(self._dataset)\n",
    "\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @cache\n",
    "    def __getitem__(self, index: int) -> Tuple[TSample, TTarget]:\n",
    "        return self._dataset[index]\n",
    "\n",
    "    def __getattr__(self, attr: str) -> Any:\n",
    "        return getattr(self._dataset, attr)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class EpochResults:\n",
    "    correct: int\n",
    "    total: int\n",
    "    loss: float\n",
    "\n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        return self.correct / self.total\n",
    "\n",
    "\n",
    "def show_samples(samples: Sequence[Tuple[Tensor, str]]) -> None:\n",
    "    size = len(samples)\n",
    "    plt.subplots(1, size, figsize=(12, 12))\n",
    "\n",
    "    for i, (sample, target) in enumerate(samples):\n",
    "        plt.subplot(1, size, i + 1)\n",
    "        plt.title(target.title())\n",
    "\n",
    "        # Normalize the image tensor from range [-1, 1] to [0, 1]\n",
    "        sample = sample / 2 + 0.5\n",
    "\n",
    "        # Convert the tensor to a NumPy array and transpose the dimensions from (channels, height, width) to (height, width, channels)\n",
    "        image = sample.numpy().transpose(1, 2, 0).squeeze()\n",
    "        plt.imshow(image)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_device() -> device:\n",
    "    if mps.is_available():\n",
    "        return device('mps')\n",
    "\n",
    "    if cuda.is_available():\n",
    "        return device('cuda')\n",
    "\n",
    "    return device('cpu')\n",
    "\n",
    "\n",
    "def do_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    device: device,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer | None = None,\n",
    ") -> EpochResults:\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch_max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return EpochResults(correct, total, running_loss / len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(150),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5) * 3, std=(0.5) * 3),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train = CachedDataset(ZipImageDataset(\"data/rps.zip\", transform=transform))\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test = CachedDataset(ZipImageDataset(\"data/rps-test-set.zip\", transform=transform))\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка предобработанных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "samples = ((s, train.classes[t]) for s, t in zip(images, labels))\n",
    "\n",
    "show_samples([*islice(samples, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_device()\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model = RPSClassifier().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_results = []\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_results = do_epoch(model, train_loader, DEVICE, criterion, optimizer)\n",
    "    train_results.append(epoch_results)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1} / {EPOCHS}, Loss: {epoch_results.loss:.4f}, Accuracy: {epoch_results.accuracy * 100:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [*range(1, EPOCHS + 1)]\n",
    "accuracies = [e.accuracy for e in train_results]\n",
    "losses = [e.loss for e in train_results]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "ax1.plot(epochs, accuracies, color=\"b\", label=\"Accuracy\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_title(\"Accuracy Over Epochs\")\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(epochs, losses, color=\"r\", label=\"Loss\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Loss Over Epochs\")\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with no_grad():\n",
    "    results = do_epoch(model, test_loader, DEVICE, criterion, None)\n",
    "\n",
    "    print(\n",
    "        f\"Test dataset, Loss: {results.loss:.4f}, Accuracy: {results.accuracy * 100:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
