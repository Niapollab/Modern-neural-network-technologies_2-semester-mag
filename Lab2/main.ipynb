{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2 \"Многослойный персептрон\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "vCvN9IfZs_Kl",
    "outputId": "b8a57ac0-951c-4ebc-e580-5877c071a5b8"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import float64, Tensor, tensor\n",
    "from torch.optim.adam import Optimizer, Adam\n",
    "from typing import Iterable, Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConfusionMatrix:\n",
    "    __true_positive: int\n",
    "    __true_negative: int\n",
    "    __false_positive: int\n",
    "    __false_negative: int\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.__true_positive = 0\n",
    "        self.__true_negative = 0\n",
    "        self.__false_positive = 0\n",
    "        self.__false_negative = 0\n",
    "\n",
    "    @property\n",
    "    def data(self) -> Sequence[Sequence[int]]:\n",
    "        return [\n",
    "            [self.__true_positive, self.__false_positive],\n",
    "            [self.__false_negative, self.__true_negative],\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        trues = self.__true_positive + self.__true_negative\n",
    "        return (trues) / (trues + self.__false_positive + self.__false_negative)\n",
    "\n",
    "    @property\n",
    "    def precision(self) -> float:\n",
    "        return self.__true_positive / (self.__true_positive + self.__false_positive)\n",
    "\n",
    "    @property\n",
    "    def recall(self) -> float:\n",
    "        return self.__true_positive / (self.__true_positive + self.__false_negative)\n",
    "\n",
    "    def accept[T](self, expected: T, actual: T) -> None:\n",
    "        if expected == actual:\n",
    "            if actual:\n",
    "                self.__true_positive += 1\n",
    "            else:\n",
    "                self.__true_negative += 1\n",
    "        else:\n",
    "            if actual:\n",
    "                self.__false_positive += 1\n",
    "            else:\n",
    "                self.__false_negative += 1\n",
    "\n",
    "    def __format__(self, format_spec: str) -> str:\n",
    "        if \"n\" in format_spec:\n",
    "            format_spec = format_spec.replace(\"n\", \"\")\n",
    "            separator = \"\\n\"\n",
    "        else:\n",
    "            separator = \", \"\n",
    "\n",
    "        accuracy = self.accuracy.__format__(format_spec)\n",
    "        precision = self.precision.__format__(format_spec)\n",
    "        recall = self.recall.__format__(format_spec)\n",
    "\n",
    "        return f\"Accuracy: {accuracy}{separator}Precision: {precision}{separator}Recall: {recall}\"\n",
    "\n",
    "\n",
    "def GradeClasifier() -> nn.Sequential:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(8, 30, dtype=float64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(30, 1, dtype=float64),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: nn.Module,\n",
    "    input: Sequence[Tensor],\n",
    "    expected_output: Sequence[Tensor],\n",
    "    *,\n",
    "    loss_fn: nn.Module | None = None,\n",
    "    optimizer: Optimizer | None = None,\n",
    ") -> ConfusionMatrix:\n",
    "    if len(input) != len(expected_output):\n",
    "        raise ValueError(\"Input length must be equals to expected_output.\")\n",
    "\n",
    "    matrix = ConfusionMatrix()\n",
    "    for x, y in zip(input, expected_output):\n",
    "        y_pred = model(x)\n",
    "        y_real = tensor([y.item()], dtype=float64)\n",
    "\n",
    "        if loss_fn is not None:\n",
    "            loss = loss_fn(y_pred, y_real)\n",
    "\n",
    "        matrix.accept(y.item(), (y_pred >= 0.5).float())\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if loss_fn is not None:\n",
    "            loss.backward()\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.step()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    input: Sequence[Tensor],\n",
    "    expected_output: Sequence[Tensor],\n",
    "    epochs: int,\n",
    "    *,\n",
    "    learning_rate: float = 0.001,\n",
    ") -> Iterable[ConfusionMatrix]:\n",
    "    if len(input) != len(expected_output):\n",
    "        raise ValueError(\"Input length must be equals to expected_output.\")\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    try:\n",
    "        for _ in range(epochs):\n",
    "            yield test(\n",
    "                model, input, expected_output, loss_fn=loss_fn, optimizer=optimizer\n",
    "            )\n",
    "    finally:\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mushroom_cleaned.csv.tar.gz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBwvHx70HvYJ",
    "outputId": "46ba796b-2dc2-468c-fc79-c00cd832f24c"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "TRAIN_PROPORTION = 2e-1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('class', axis=1), df['class'], test_size=TRAIN_PROPORTION, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"cap-diameter\", \"stem-height\"]\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train[columns] = scaler.fit_transform(X_train[columns])\n",
    "X_test[columns] = scaler.transform(X_test[columns])\n",
    "\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    tensor(X_train.values, dtype=float64),\n",
    "    tensor(X_test.values, dtype=float64),\n",
    "    tensor(y_train.values, dtype=float64),\n",
    "    tensor(y_test.values, dtype=float64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 80\n",
    "\n",
    "model = GradeClasifier()\n",
    "matrixes = [*train(model, X_train, y_train, EPOCHS)]\n",
    "\n",
    "epochs = [*range(1, len(matrixes) + 1)]\n",
    "accuracies = [matrix.accuracy for matrix in matrixes]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, accuracies, color='b', label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = test(model, X_test, y_test)\n",
    "labels = np.array(\n",
    "    [[\"True Positive\", \"False Positive\"], [\"False Negative\", \"True Negative\"]]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    matrix.data,\n",
    "    annot=labels,\n",
    "    fmt=\"\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    xticklabels=[\"Positive\", \"Negative\"],\n",
    "    yticklabels=[\"Actual Positive\", \"Actual Negative\"],\n",
    ")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n",
    "metrics_text = f\"{matrix:n.2f}\"\n",
    "plt.text(\n",
    "    1.5,\n",
    "    -0.5,\n",
    "    metrics_text,\n",
    "    fontsize=12,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
